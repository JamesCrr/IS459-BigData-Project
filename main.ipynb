{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce1bb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found in local data folder: ['airline.csv.shuffle', 'carriers.csv']\n",
      "Both files found locally, using local data...\n",
      "Dataset path: ./data/\n",
      "Airline file: ./data/airline.csv.shuffle\n",
      "Carriers file: ./data/carriers.csv\n",
      "Airline file size: 11471.95 MB\n",
      "First 3 lines of airline.csv.shuffle:\n",
      "Line 1: ActualElapsedTime,AirTime,ArrDelay,ArrTime,CRSArrTime,CRSDepTime,CRSElapsedTime,CancellationCode,Cancelled,CarrierDelay,DayOfWeek,DayofMonth,DepDelay,DepTime,Dest,Distance,Diverted,FlightNum,LateAircraftDelay,Month,NASDelay,Origin,SecurityDelay,TailNum,TaxiIn,TaxiOut,UniqueCarrier,WeatherDelay,Year\n",
      "Line 2: 53,32,-8,1642,1650,1545,65,NA,0,NA,4,10,4,1549,PIT,205,0,209,NA,10,NA,DCA,NA,N443US,7,14,US,NA,2002\n",
      "Line 3: 164,155,-11,1754,1805,1610,175,NA,0,NA,4,2,0,1610,MCI,1072,0,109,NA,12,NA,MCO,NA,N755,2,7,WN,NA,1999\n",
      "Carriers file size: 0.04 MB\n",
      "First 5 lines of carriers.csv:\n",
      "Line 1: Code,Description\n",
      "Line 2: \"02Q\",\"Titan Airways\"\n",
      "Line 3: \"04Q\",\"Tradewind Aviation\"\n",
      "Line 4: \"05Q\",\"Comlux Aviation, AG\"\n",
      "Line 5: \"06Q\",\"Master Top Linhas Aereas Ltd.\"\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if data already exists locally first\n",
    "local_data_path = \"./data/\"\n",
    "airline_file = \"airline.csv.shuffle\"\n",
    "carriers_file = \"carriers.csv\"\n",
    "\n",
    "if os.path.exists(local_data_path):\n",
    "    local_files = os.listdir(local_data_path)\n",
    "    print(f\"Files found in local data folder: {local_files}\")\n",
    "    \n",
    "    # Check if both required files exist locally\n",
    "    airline_exists = airline_file in local_files\n",
    "    carriers_exists = carriers_file in local_files\n",
    "    \n",
    "    if airline_exists and carriers_exists:\n",
    "        print(\"Both files found locally, using local data...\")\n",
    "        path = local_data_path\n",
    "        airline_file_path = os.path.join(path, airline_file)\n",
    "        carriers_file_path = os.path.join(path, carriers_file)\n",
    "    else:\n",
    "        missing_files = []\n",
    "        if not airline_exists:\n",
    "            missing_files.append(airline_file)\n",
    "        if not carriers_exists:\n",
    "            missing_files.append(carriers_file)\n",
    "        print(f\"Missing local files: {missing_files}, downloading from Kaggle...\")\n",
    "        \n",
    "        # Download the dataset from Kaggle\n",
    "        path = kagglehub.dataset_download(\"bulter22/airline-data\")\n",
    "        print(f\"Dataset downloaded to: {path}\")\n",
    "        airline_file_path = os.path.join(path, airline_file)\n",
    "        carriers_file_path = os.path.join(path, carriers_file)\n",
    "else:\n",
    "    print(\"Local data folder doesn't exist, downloading from Kaggle...\")\n",
    "    # Download the dataset from Kaggle\n",
    "    path = kagglehub.dataset_download(\"bulter22/airline-data\")\n",
    "    print(f\"Dataset downloaded to: {path}\")\n",
    "    airline_file_path = os.path.join(path, airline_file)\n",
    "    carriers_file_path = os.path.join(path, carriers_file)\n",
    "\n",
    "print(f\"Dataset path: {path}\")\n",
    "print(f\"Airline file: {airline_file_path}\")\n",
    "print(f\"Carriers file: {carriers_file_path}\")\n",
    "\n",
    "# Check file sizes\n",
    "if os.path.exists(airline_file_path):\n",
    "    airline_size = os.path.getsize(airline_file_path)\n",
    "    print(f\"Airline file size: {airline_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Read first few lines of airline file\n",
    "    with open(airline_file_path, 'r') as f:\n",
    "        airline_first_lines = [f.readline().strip() for _ in range(3)]\n",
    "    print(\"First 3 lines of airline.csv.shuffle:\")\n",
    "    for i, line in enumerate(airline_first_lines, 1):\n",
    "        print(f\"Line {i}: {line}\")\n",
    "\n",
    "if os.path.exists(carriers_file_path):\n",
    "    carriers_size = os.path.getsize(carriers_file_path)\n",
    "    print(f\"Carriers file size: {carriers_size / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    # Read first few lines of carriers file\n",
    "    with open(carriers_file_path, 'r') as f:\n",
    "        carriers_first_lines = [f.readline().strip() for _ in range(5)]\n",
    "    print(\"First 5 lines of carriers.csv:\")\n",
    "    for i, line in enumerate(carriers_first_lines, 1):\n",
    "        print(f\"Line {i}: {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bgtmzytz6oe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING DATASETS WITH SMART SAMPLING ===\n",
      "=== INITIAL MEMORY STATE ===\n",
      "Total RAM: 14.77 GB\n",
      "Available: 7.79 GB\n",
      "Used: 6.98 GB (47.2%)\n",
      "\n",
      "Airline data file size: 11.20 GB\n",
      "Available memory: 7.79 GB\n",
      "Using analysis sampling: 500,000 rows\n",
      "Trying latin-1 encoding with 500,000 rows...\n",
      "✓ Airline data loaded successfully with latin-1: (500000, 29)\n",
      "Columns: ['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSArrTime', 'CRSDepTime', 'CRSElapsedTime', 'CancellationCode', 'Cancelled', 'CarrierDelay', 'DayOfWeek', 'DayofMonth', 'DepDelay', 'DepTime', 'Dest', 'Distance', 'Diverted', 'FlightNum', 'LateAircraftDelay', 'Month', 'NASDelay', 'Origin', 'SecurityDelay', 'TailNum', 'TaxiIn', 'TaxiOut', 'UniqueCarrier', 'WeatherDelay', 'Year']\n",
      "DataFrame memory usage: 203.77 MB\n",
      "\n",
      "Carriers data file size: 0.00 GB\n",
      "Available memory: 7.79 GB\n",
      "Loading full dataset...\n",
      "Trying latin-1 encoding...\n",
      "✓ Carriers data loaded successfully with latin-1: (1491, 2)\n",
      "Columns: ['Code', 'Description']\n",
      "DataFrame memory usage: 0.17 MB\n",
      "\n",
      "=== MEMORY STATE AFTER LOADING ===\n",
      "Available: 7.80 GB\n",
      "Used: 6.97 GB (47.2%)\n",
      "Additional memory used: -0.01 GB\n",
      "\n",
      "=== AIRLINE DATA SAMPLE (Shape: (500000, 29)) ===\n",
      "   ActualElapsedTime  AirTime  ArrDelay  ArrTime  CRSArrTime  CRSDepTime  \\\n",
      "0               53.0     32.0      -8.0   1642.0        1650        1545   \n",
      "1              164.0    155.0     -11.0   1754.0        1805        1610   \n",
      "2               60.0      NaN      15.0   2005.0        1950        1850   \n",
      "3               51.0      NaN      -5.0   1818.0        1823        1728   \n",
      "4               45.0     29.0       2.0   1120.0        1118        1030   \n",
      "\n",
      "   CRSElapsedTime CancellationCode  Cancelled  CarrierDelay  ...  Month  \\\n",
      "0            65.0              NaN          0           NaN  ...     10   \n",
      "1           175.0              NaN          0           NaN  ...     12   \n",
      "2            60.0              NaN          0           NaN  ...     12   \n",
      "3            55.0              NaN          0           NaN  ...      9   \n",
      "4            48.0              NaN          0           0.0  ...      6   \n",
      "\n",
      "   NASDelay  Origin  SecurityDelay TailNum  TaxiIn  TaxiOut  UniqueCarrier  \\\n",
      "0       NaN     DCA            NaN  N443US     7.0     14.0             US   \n",
      "1       NaN     MCO            NaN    N755     2.0      7.0             WN   \n",
      "2       NaN     ATL            NaN     NaN     NaN      NaN             DL   \n",
      "3       NaN     MEM            NaN     NaN     NaN      NaN             AA   \n",
      "4       0.0     CVG            0.0  N785CA     3.0     13.0             OH   \n",
      "\n",
      "   WeatherDelay  Year  \n",
      "0           NaN  2002  \n",
      "1           NaN  1999  \n",
      "2           NaN  1993  \n",
      "3           NaN  1989  \n",
      "4           0.0  2006  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "Data types:\n",
      "ActualElapsedTime    float64\n",
      "AirTime              float64\n",
      "ArrDelay             float64\n",
      "ArrTime              float64\n",
      "CRSArrTime             int64\n",
      "CRSDepTime             int64\n",
      "CRSElapsedTime       float64\n",
      "CancellationCode      object\n",
      "Cancelled              int64\n",
      "CarrierDelay         float64\n",
      "DayOfWeek              int64\n",
      "DayofMonth             int64\n",
      "DepDelay             float64\n",
      "DepTime              float64\n",
      "Dest                  object\n",
      "Distance             float64\n",
      "Diverted               int64\n",
      "FlightNum              int64\n",
      "LateAircraftDelay    float64\n",
      "Month                  int64\n",
      "NASDelay             float64\n",
      "Origin                object\n",
      "SecurityDelay        float64\n",
      "TailNum               object\n",
      "TaxiIn               float64\n",
      "TaxiOut              float64\n",
      "UniqueCarrier         object\n",
      "WeatherDelay         float64\n",
      "Year                   int64\n",
      "dtype: object\n",
      "\n",
      "=== CARRIERS DATA SAMPLE (Shape: (1491, 2)) ===\n",
      "  Code                    Description\n",
      "0  02Q                  Titan Airways\n",
      "1  04Q             Tradewind Aviation\n",
      "2  05Q            Comlux Aviation, AG\n",
      "3  06Q  Master Top Linhas Aereas Ltd.\n",
      "4  07Q            Flair Airlines Ltd.\n",
      "\n",
      "Data types:\n",
      "Code           object\n",
      "Description    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load both datasets with smart sampling for large files\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== LOADING DATASETS WITH SMART SAMPLING ===\")\n",
    "\n",
    "def get_memory_info():\n",
    "    \"\"\"Get current memory usage information\"\"\"\n",
    "    memory = psutil.virtual_memory()\n",
    "    return {\n",
    "        'total_gb': memory.total / (1024**3),\n",
    "        'available_gb': memory.available / (1024**3),\n",
    "        'used_gb': memory.used / (1024**3),\n",
    "        'percent': memory.percent\n",
    "    }\n",
    "\n",
    "def smart_load_csv(file_path, dataset_name, sample_size='auto'):\n",
    "    \"\"\"\n",
    "    Smart CSV loader that handles large files with sampling\n",
    "    \n",
    "    sample_size options:\n",
    "    - 'auto': Automatically choose based on file size\n",
    "    - 'quick': 10,000 rows for quick testing\n",
    "    - 'dev': 100,000 rows for development\n",
    "    - 'analysis': 500,000 rows for analysis\n",
    "    - integer: specific number of rows\n",
    "    - 'full': load entire file (use with caution)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check file size\n",
    "    file_size_bytes = os.path.getsize(file_path)\n",
    "    file_size_gb = file_size_bytes / (1024**3)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} file size: {file_size_gb:.2f} GB\")\n",
    "    \n",
    "    # Get memory info\n",
    "    mem_info = get_memory_info()\n",
    "    print(f\"Available memory: {mem_info['available_gb']:.2f} GB\")\n",
    "    \n",
    "    # Determine sample size\n",
    "    if sample_size == 'auto':\n",
    "        if file_size_gb > 1.0:  # If file > 1GB, use sampling\n",
    "            if file_size_gb > 10.0:\n",
    "                sample_size = 'analysis'  # 500K rows for very large files\n",
    "            else:\n",
    "                sample_size = 'dev'  # 100K rows for moderately large files\n",
    "        else:\n",
    "            sample_size = 'full'\n",
    "    \n",
    "    # Convert sample size to number\n",
    "    size_map = {\n",
    "        'quick': 10000,\n",
    "        'dev': 100000, \n",
    "        'analysis': 500000\n",
    "    }\n",
    "    \n",
    "    if isinstance(sample_size, str) and sample_size in size_map:\n",
    "        n_rows = size_map[sample_size]\n",
    "        print(f\"Using {sample_size} sampling: {n_rows:,} rows\")\n",
    "    elif isinstance(sample_size, int):\n",
    "        n_rows = sample_size\n",
    "        print(f\"Using custom sampling: {n_rows:,} rows\")\n",
    "    elif sample_size == 'full':\n",
    "        n_rows = None\n",
    "        print(\"Loading full dataset...\")\n",
    "    else:\n",
    "        n_rows = 100000  # Default fallback\n",
    "        print(f\"Using default sampling: {n_rows:,} rows\")\n",
    "    \n",
    "    # Load with encoding handling\n",
    "    # encodings = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252']\n",
    "    encodings = ['latin-1']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            if n_rows is None:\n",
    "                # Load full file\n",
    "                print(f\"Trying {encoding} encoding...\")\n",
    "                df = pd.read_csv(file_path, encoding=encoding)\n",
    "            else:\n",
    "                # Sample approach: read first n_rows for now (can be enhanced to random sampling)\n",
    "                print(f\"Trying {encoding} encoding with {n_rows:,} rows...\")\n",
    "                df = pd.read_csv(file_path, encoding=encoding, nrows=n_rows)\n",
    "                \n",
    "            print(f\"✓ {dataset_name} loaded successfully with {encoding}: {df.shape}\")\n",
    "            print(f\"Columns: {list(df.columns)}\")\n",
    "            \n",
    "            # Memory usage of loaded dataframe\n",
    "            df_memory_mb = df.memory_usage(deep=True).sum() / (1024**2)\n",
    "            print(f\"DataFrame memory usage: {df_memory_mb:.2f} MB\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"  {encoding} failed due to encoding issues\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"  {encoding} failed: {str(e)[:100]}...\")\n",
    "            continue\n",
    "    \n",
    "    # Final fallback with error replacement\n",
    "    try:\n",
    "        print(f\"Trying utf-8 with error handling...\")\n",
    "        if n_rows is None:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8', encoding_errors='replace')\n",
    "        else:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8', encoding_errors='replace', nrows=n_rows)\n",
    "        print(f\"✓ {dataset_name} loaded with error replacement: {df.shape}\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"All methods failed for {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Show initial memory state\n",
    "print(\"=== INITIAL MEMORY STATE ===\")\n",
    "initial_memory = get_memory_info()\n",
    "print(f\"Total RAM: {initial_memory['total_gb']:.2f} GB\")\n",
    "print(f\"Available: {initial_memory['available_gb']:.2f} GB\") \n",
    "print(f\"Used: {initial_memory['used_gb']:.2f} GB ({initial_memory['percent']:.1f}%)\")\n",
    "\n",
    "# Load airline data with smart sampling\n",
    "df_airline = smart_load_csv(airline_file_path, \"Airline data\", sample_size='auto')\n",
    "\n",
    "# Load carriers data (usually smaller, so can load fully)\n",
    "df_carriers = smart_load_csv(carriers_file_path, \"Carriers data\", sample_size='full')\n",
    "\n",
    "# Show final memory state\n",
    "print(\"\\n=== MEMORY STATE AFTER LOADING ===\")\n",
    "final_memory = get_memory_info()\n",
    "print(f\"Available: {final_memory['available_gb']:.2f} GB\")\n",
    "print(f\"Used: {final_memory['used_gb']:.2f} GB ({final_memory['percent']:.1f}%)\")\n",
    "memory_used = final_memory['used_gb'] - initial_memory['used_gb']\n",
    "print(f\"Additional memory used: {memory_used:.2f} GB\")\n",
    "\n",
    "# Display sample data\n",
    "if df_airline is not None:\n",
    "    print(f\"\\n=== AIRLINE DATA SAMPLE (Shape: {df_airline.shape}) ===\")\n",
    "    print(df_airline.head())\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df_airline.dtypes)\n",
    "\n",
    "if df_carriers is not None:\n",
    "    print(f\"\\n=== CARRIERS DATA SAMPLE (Shape: {df_carriers.shape}) ===\")\n",
    "    print(df_carriers.head())\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df_carriers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u68zzcczql",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Load different sample sizes for testing\n",
    "print(\"=== SAMPLE SIZE OPTIONS ===\")\n",
    "print(\"You can reload the airline data with different sample sizes:\")\n",
    "print(\"- smart_load_csv(airline_file_path, 'Airline data', 'quick')     # 10K rows\")\n",
    "print(\"- smart_load_csv(airline_file_path, 'Airline data', 'dev')       # 100K rows\") \n",
    "print(\"- smart_load_csv(airline_file_path, 'Airline data', 'analysis')  # 500K rows\")\n",
    "print(\"- smart_load_csv(airline_file_path, 'Airline data', 50000)       # Custom: 50K rows\")\n",
    "\n",
    "# Example: Load a quick sample for rapid testing\n",
    "print(\"\\n=== LOADING QUICK SAMPLE FOR TESTING ===\")\n",
    "df_airline_quick = smart_load_csv(airline_file_path, \"Airline data (Quick)\", 'quick')\n",
    "\n",
    "if df_airline_quick is not None:\n",
    "    print(f\"\\nQuick sample summary:\")\n",
    "    print(f\"Shape: {df_airline_quick.shape}\")\n",
    "    print(f\"Columns: {list(df_airline_quick.columns)}\")\n",
    "    print(f\"Memory usage: {df_airline_quick.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # Show data quality info\n",
    "    print(f\"\\nData quality check:\")\n",
    "    print(f\"Missing values: {df_airline_quick.isnull().sum().sum()}\")\n",
    "    print(f\"Duplicate rows: {df_airline_quick.duplicated().sum()}\")\n",
    "    \n",
    "    # Show sample of data\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_airline_quick.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cr8m98mv5ui",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AIRLINE ANALYSIS ===\n",
      "Dataset shape: (500000, 29)\n",
      "Memory usage: 203.77 MB\n",
      "\n",
      "=== AIRLINE COLUMN INFORMATION ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   ActualElapsedTime  489361 non-null  float64\n",
      " 1   AirTime            340591 non-null  float64\n",
      " 2   ArrDelay           489361 non-null  float64\n",
      " 3   ArrTime            489370 non-null  float64\n",
      " 4   CRSArrTime         500000 non-null  int64  \n",
      " 5   CRSDepTime         500000 non-null  int64  \n",
      " 6   CRSElapsedTime     499894 non-null  float64\n",
      " 7   CancellationCode   2948 non-null    object \n",
      " 8   Cancelled          500000 non-null  int64  \n",
      " 9   CarrierDelay       138091 non-null  float64\n",
      " 10  DayOfWeek          500000 non-null  int64  \n",
      " 11  DayofMonth         500000 non-null  int64  \n",
      " 12  DepDelay           490539 non-null  float64\n",
      " 13  DepTime            490539 non-null  float64\n",
      " 14  Dest               500000 non-null  object \n",
      " 15  Distance           499152 non-null  float64\n",
      " 16  Diverted           500000 non-null  int64  \n",
      " 17  FlightNum          500000 non-null  int64  \n",
      " 18  LateAircraftDelay  138091 non-null  float64\n",
      " 19  Month              500000 non-null  int64  \n",
      " 20  NASDelay           138091 non-null  float64\n",
      " 21  Origin             500000 non-null  object \n",
      " 22  SecurityDelay      138091 non-null  float64\n",
      " 23  TailNum            348309 non-null  object \n",
      " 24  TaxiIn             348249 non-null  float64\n",
      " 25  TaxiOut            348303 non-null  float64\n",
      " 26  UniqueCarrier      500000 non-null  object \n",
      " 27  WeatherDelay       138091 non-null  float64\n",
      " 28  Year               500000 non-null  int64  \n",
      "dtypes: float64(15), int64(9), object(5)\n",
      "memory usage: 110.6+ MB\n",
      "None\n",
      "\n",
      "=== AIRLINE DATA TYPES ===\n",
      "float64    15\n",
      "int64       9\n",
      "object      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== AIRLINE MISSING VALUES ===\n",
      "                   Missing Count  Missing Percentage\n",
      "CancellationCode          497052             99.4104\n",
      "CarrierDelay              361909             72.3818\n",
      "WeatherDelay              361909             72.3818\n",
      "LateAircraftDelay         361909             72.3818\n",
      "NASDelay                  361909             72.3818\n",
      "SecurityDelay             361909             72.3818\n",
      "AirTime                   159409             31.8818\n",
      "TaxiIn                    151751             30.3502\n",
      "TaxiOut                   151697             30.3394\n",
      "TailNum                   151691             30.3382\n",
      "ActualElapsedTime          10639              2.1278\n",
      "ArrDelay                   10639              2.1278\n",
      "ArrTime                    10630              2.1260\n",
      "DepDelay                    9461              1.8922\n",
      "DepTime                     9461              1.8922\n",
      "Distance                     848              0.1696\n",
      "CRSElapsedTime               106              0.0212\n",
      "\n",
      "=== AIRLINE DESCRIPTIVE STATISTICS ===\n",
      "       ActualElapsedTime        AirTime       ArrDelay        ArrTime  \\\n",
      "count      489361.000000  340591.000000  489361.000000  489370.000000   \n",
      "mean          120.129585     102.837239       7.075864    1493.339015   \n",
      "std            68.660225      70.711032      30.986089     498.335782   \n",
      "min          -525.000000   -1419.000000   -1410.000000       1.000000   \n",
      "25%            70.000000      54.000000      -7.000000    1116.000000   \n",
      "50%           101.000000      84.000000       0.000000    1522.000000   \n",
      "75%           151.000000     133.000000      11.000000    1916.000000   \n",
      "max          1538.000000    1570.000000    1430.000000    2717.000000   \n",
      "\n",
      "          CRSArrTime     CRSDepTime  CRSElapsedTime      Cancelled  \\\n",
      "count  500000.000000  500000.000000   499894.000000  500000.000000   \n",
      "mean     1490.513416    1333.993458      121.011873       0.018930   \n",
      "std       493.254339     476.330266       68.054242       0.136278   \n",
      "min         0.000000       0.000000      -30.000000       0.000000   \n",
      "25%      1115.000000     929.000000       71.000000       0.000000   \n",
      "50%      1520.000000    1326.000000      102.000000       0.000000   \n",
      "75%      1912.000000    1727.000000      152.000000       0.000000   \n",
      "max      2400.000000    2359.000000      660.000000       1.000000   \n",
      "\n",
      "        CarrierDelay      DayOfWeek  ...       Diverted      FlightNum  \\\n",
      "count  138091.000000  500000.000000  ...  500000.000000  500000.000000   \n",
      "mean        3.771556       3.941264  ...       0.002348    1364.928906   \n",
      "std        20.393489       1.988253  ...       0.048399    1405.752609   \n",
      "min         0.000000       1.000000  ...       0.000000       1.000000   \n",
      "25%         0.000000       2.000000  ...       0.000000     450.000000   \n",
      "50%         0.000000       4.000000  ...       0.000000     944.500000   \n",
      "75%         0.000000       6.000000  ...       0.000000    1710.000000   \n",
      "max      1126.000000       7.000000  ...       1.000000    9583.000000   \n",
      "\n",
      "       LateAircraftDelay          Month       NASDelay  SecurityDelay  \\\n",
      "count      138091.000000  500000.000000  138091.000000  138091.000000   \n",
      "mean            4.690747       6.555906       4.061344       0.023550   \n",
      "std            19.831381       3.444046      16.544047       0.964131   \n",
      "min             0.000000       1.000000       0.000000       0.000000   \n",
      "25%             0.000000       4.000000       0.000000       0.000000   \n",
      "50%             0.000000       7.000000       0.000000       0.000000   \n",
      "75%             0.000000      10.000000       0.000000       0.000000   \n",
      "max           562.000000      12.000000     875.000000     126.000000   \n",
      "\n",
      "              TaxiIn        TaxiOut   WeatherDelay           Year  \n",
      "count  348249.000000  348303.000000  138091.000000  500000.000000  \n",
      "mean        6.456174      15.213659       0.745957    1998.610982  \n",
      "std        21.519309      10.912041       8.630243       6.224209  \n",
      "min         0.000000       0.000000       0.000000    1987.000000  \n",
      "25%         4.000000      10.000000       0.000000    1993.000000  \n",
      "50%         5.000000      13.000000       0.000000    1999.000000  \n",
      "75%         7.000000      18.000000       0.000000    2004.000000  \n",
      "max      1460.000000    1060.000000     638.000000    2008.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "\n",
      "=== AIRLINE CATEGORICAL COLUMNS ===\n",
      "'CancellationCode': 4 unique values\n",
      "  Values: [nan, 'B', 'A', 'C', 'D']\n",
      "'Dest': 329 unique values\n",
      "'Origin': 329 unique values\n",
      "'TailNum': 12713 unique values\n",
      "'UniqueCarrier': 29 unique values\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== CARRIERS ANALYSIS ===\n",
      "Dataset shape: (1491, 2)\n",
      "Memory usage: 0.17 MB\n",
      "\n",
      "=== CARRIERS COLUMN INFORMATION ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1491 entries, 0 to 1490\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Code         1490 non-null   object\n",
      " 1   Description  1491 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 23.4+ KB\n",
      "None\n",
      "\n",
      "=== CARRIERS DATA TYPES ===\n",
      "object    2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== CARRIERS MISSING VALUES ===\n",
      "      Missing Count  Missing Percentage\n",
      "Code              1            0.067069\n",
      "\n",
      "=== CARRIERS DESCRIPTIVE STATISTICS ===\n",
      "        Code    Description\n",
      "count   1490           1491\n",
      "unique  1490           1491\n",
      "top      02Q  Titan Airways\n",
      "freq       1              1\n",
      "\n",
      "=== CARRIERS CATEGORICAL COLUMNS ===\n",
      "'Code': 1490 unique values\n",
      "'Description': 1491 unique values\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== DATASET RELATIONSHIP ANALYSIS ===\n",
      "Common columns: []\n",
      "Carriers has 'Code' column - can be used as lookup table\n",
      "Potential carrier code columns in airline data: ['CancellationCode', 'CarrierDelay', 'UniqueCarrier']\n",
      "Airline dataset: 500,000 rows\n",
      "Carriers dataset: 1,491 rows\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis for both datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_dataset(df, dataset_name):\n",
    "    print(f\"=== {dataset_name.upper()} ANALYSIS ===\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name.upper()} COLUMN INFORMATION ===\")\n",
    "    print(df.info())\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name.upper()} DATA TYPES ===\")\n",
    "    print(df.dtypes.value_counts())\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name.upper()} MISSING VALUES ===\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percent = (missing_values / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing_values,\n",
    "        'Missing Percentage': missing_percent\n",
    "    }).sort_values('Missing Percentage', ascending=False)\n",
    "    missing_summary = missing_df[missing_df['Missing Count'] > 0]\n",
    "    if len(missing_summary) > 0:\n",
    "        print(missing_summary)\n",
    "    else:\n",
    "        print(\"No missing values found!\")\n",
    "    \n",
    "    print(f\"\\n=== {dataset_name.upper()} DESCRIPTIVE STATISTICS ===\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Show unique values for categorical columns (if not too many)\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\n=== {dataset_name.upper()} CATEGORICAL COLUMNS ===\")\n",
    "        for col in categorical_cols:\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"'{col}': {unique_count} unique values\")\n",
    "            if unique_count <= 20:  # Show unique values if not too many\n",
    "                print(f\"  Values: {list(df[col].unique())}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Analyze airline dataset\n",
    "if df_airline is not None:\n",
    "    analyze_dataset(df_airline, \"AIRLINE\")\n",
    "\n",
    "# Analyze carriers dataset  \n",
    "if df_carriers is not None:\n",
    "    analyze_dataset(df_carriers, \"CARRIERS\")\n",
    "\n",
    "# Check for potential relationship between datasets\n",
    "if df_airline is not None and df_carriers is not None:\n",
    "    print(\"=== DATASET RELATIONSHIP ANALYSIS ===\")\n",
    "    \n",
    "    # Look for common columns\n",
    "    airline_cols = set(df_airline.columns)\n",
    "    carriers_cols = set(df_carriers.columns)\n",
    "    common_cols = airline_cols.intersection(carriers_cols)\n",
    "    \n",
    "    print(f\"Common columns: {list(common_cols)}\")\n",
    "    \n",
    "    # Check if carriers data can be used as lookup table\n",
    "    if 'Code' in df_carriers.columns or 'code' in df_carriers.columns:\n",
    "        carrier_code_col = 'Code' if 'Code' in df_carriers.columns else 'code'\n",
    "        print(f\"Carriers has '{carrier_code_col}' column - can be used as lookup table\")\n",
    "        \n",
    "        # Check if airline data has corresponding carrier codes\n",
    "        potential_carrier_cols = [col for col in df_airline.columns if 'carrier' in col.lower() or 'code' in col.lower()]\n",
    "        if potential_carrier_cols:\n",
    "            print(f\"Potential carrier code columns in airline data: {potential_carrier_cols}\")\n",
    "    \n",
    "    print(f\"Airline dataset: {df_airline.shape[0]:,} rows\")\n",
    "    print(f\"Carriers dataset: {df_carriers.shape[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pn6zrigegm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA CLEANING ===\n",
      "\n",
      "=== CLEANING AIRLINE DATASET ===\n",
      "Starting with 500000 rows and 29 columns\n",
      "Removed 0 completely empty rows\n",
      "Removed 0 duplicate rows\n",
      "\n",
      "=== HANDLING MISSING VALUES FOR AIRLINE ===\n",
      "Numeric columns: 24\n",
      "Categorical columns: 5\n",
      "Datetime columns: 0\n",
      "Filled 10639 missing values in 'ActualElapsedTime' with median: 101.0\n",
      "Filled 159409 missing values in 'AirTime' with median: 84.0\n",
      "Filled 10639 missing values in 'ArrDelay' with median: 0.0\n",
      "Filled 10630 missing values in 'ArrTime' with median: 1522.0\n",
      "Filled 106 missing values in 'CRSElapsedTime' with median: 102.0\n",
      "Filled 361909 missing values in 'CarrierDelay' with median: 0.0\n",
      "Filled 9461 missing values in 'DepDelay' with median: 0.0\n",
      "Filled 9461 missing values in 'DepTime' with median: 1333.0\n",
      "Filled 848 missing values in 'Distance' with median: 544.0\n",
      "Filled 361909 missing values in 'LateAircraftDelay' with median: 0.0\n",
      "Filled 361909 missing values in 'NASDelay' with median: 0.0\n",
      "Filled 361909 missing values in 'SecurityDelay' with median: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(mode_val[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled 151751 missing values in 'TaxiIn' with median: 5.0\n",
      "Filled 151697 missing values in 'TaxiOut' with median: 13.0\n",
      "Filled 361909 missing values in 'WeatherDelay' with median: 0.0\n",
      "Filled 497052 missing values in 'CancellationCode' with mode: 'A'\n",
      "Filled 151691 missing values in 'TailNum' with mode: 'UNKNOW'\n",
      "\n",
      "=== OUTLIER DETECTION FOR AIRLINE ===\n",
      "Column 'ActualElapsedTime': 21496 outliers detected (bounds: -50.00 to 270.00)\n",
      "Column 'AirTime': 49395 outliers detected (bounds: 4.50 to 168.50)\n",
      "Column 'ArrDelay': 40704 outliers detected (bounds: -34.00 to 38.00)\n",
      "Column 'CRSElapsedTime': 20878 outliers detected (bounds: -50.50 to 273.50)\n",
      "Column 'Cancelled': 9465 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'CarrierDelay': 15060 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'DepDelay': 67224 outliers detected (bounds: -14.00 to 18.00)\n",
      "Column 'Distance': 23814 outliers detected (bounds: -636.50 to 1879.50)\n",
      "Column 'Diverted': 1174 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'FlightNum': 42853 outliers detected (bounds: -1440.00 to 3600.00)\n",
      "Column 'LateAircraftDelay': 15171 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'NASDelay': 20645 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'SecurityDelay': 172 outliers detected (bounds: 0.00 to 0.00)\n",
      "Column 'TaxiIn': 53964 outliers detected (bounds: 1.00 to 9.00)\n",
      "Column 'TaxiOut': 64963 outliers detected (bounds: 5.00 to 21.00)\n",
      "Column 'WeatherDelay': 2453 outliers detected (bounds: 0.00 to 0.00)\n",
      "\n",
      "=== AIRLINE CLEANING SUMMARY ===\n",
      "Original shape: (500000, 29)\n",
      "Final shape: (500000, 29)\n",
      "Rows removed: 0\n",
      "Remaining missing values: 0\n",
      "Clean airline dataset available as 'df_airline_clean'\n",
      "\n",
      "=== CLEANING CARRIERS DATASET ===\n",
      "Starting with 1491 rows and 2 columns\n",
      "Removed 0 completely empty rows\n",
      "Removed 0 duplicate rows\n",
      "\n",
      "=== HANDLING MISSING VALUES FOR CARRIERS ===\n",
      "Numeric columns: 0\n",
      "Categorical columns: 2\n",
      "Datetime columns: 0\n",
      "Filled 1 missing values in 'Code' with mode: '02Q'\n",
      "\n",
      "=== OUTLIER DETECTION FOR CARRIERS ===\n",
      "\n",
      "=== CARRIERS CLEANING SUMMARY ===\n",
      "Original shape: (1491, 2)\n",
      "Final shape: (1491, 2)\n",
      "Rows removed: 0\n",
      "Remaining missing values: 0\n",
      "Clean carriers dataset available as 'df_carriers_clean'\n",
      "\n",
      "=== OVERALL CLEANING COMPLETED ===\n",
      "Both datasets cleaned successfully!\n",
      "- df_airline_clean: (500000, 29)\n",
      "- df_carriers_clean: (1491, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei\\AppData\\Local\\Temp\\ipykernel_10536\\805443219.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_clean[col].fillna(mode_val[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning for both datasets\n",
    "print(\"=== DATA CLEANING ===\")\n",
    "\n",
    "def clean_dataset(df, dataset_name):\n",
    "    print(f\"\\n=== CLEANING {dataset_name.upper()} DATASET ===\")\n",
    "    \n",
    "    # Create a copy for cleaning\n",
    "    df_clean = df.copy()\n",
    "    original_shape = df_clean.shape\n",
    "    \n",
    "    print(f\"Starting with {original_shape[0]} rows and {original_shape[1]} columns\")\n",
    "    \n",
    "    # 1. Remove completely empty rows\n",
    "    empty_rows_before = df_clean.isnull().all(axis=1).sum()\n",
    "    df_clean = df_clean.dropna(how='all')\n",
    "    print(f\"Removed {empty_rows_before} completely empty rows\")\n",
    "    \n",
    "    # 2. Remove duplicate rows\n",
    "    duplicates_before = df_clean.duplicated().sum()\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"Removed {duplicates_before} duplicate rows\")\n",
    "    \n",
    "    # 3. Handle missing values for each column type\n",
    "    print(f\"\\n=== HANDLING MISSING VALUES FOR {dataset_name.upper()} ===\")\n",
    "    \n",
    "    # Identify column types\n",
    "    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    datetime_cols = df_clean.select_dtypes(include=['datetime64']).columns\n",
    "    \n",
    "    print(f\"Numeric columns: {len(numeric_cols)}\")\n",
    "    print(f\"Categorical columns: {len(categorical_cols)}\")\n",
    "    print(f\"Datetime columns: {len(datetime_cols)}\")\n",
    "    \n",
    "    # Handle missing values in numeric columns\n",
    "    for col in numeric_cols:\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            # Fill with median for numeric columns\n",
    "            median_val = df_clean[col].median()\n",
    "            df_clean[col].fillna(median_val, inplace=True)\n",
    "            print(f\"Filled {missing_count} missing values in '{col}' with median: {median_val}\")\n",
    "    \n",
    "    # Handle missing values in categorical columns\n",
    "    for col in categorical_cols:\n",
    "        missing_count = df_clean[col].isnull().sum()\n",
    "        if missing_count > 0:\n",
    "            # Fill with mode (most frequent value) for categorical columns\n",
    "            mode_val = df_clean[col].mode()\n",
    "            if len(mode_val) > 0:\n",
    "                df_clean[col].fillna(mode_val[0], inplace=True)\n",
    "                print(f\"Filled {missing_count} missing values in '{col}' with mode: '{mode_val[0]}'\")\n",
    "            else:\n",
    "                df_clean[col].fillna('Unknown', inplace=True)\n",
    "                print(f\"Filled {missing_count} missing values in '{col}' with 'Unknown'\")\n",
    "    \n",
    "    # 4. Handle outliers (for numeric columns)\n",
    "    print(f\"\\n=== OUTLIER DETECTION FOR {dataset_name.upper()} ===\")\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()\n",
    "        if outliers > 0:\n",
    "            print(f\"Column '{col}': {outliers} outliers detected (bounds: {lower_bound:.2f} to {upper_bound:.2f})\")\n",
    "    \n",
    "    # 5. Final summary\n",
    "    final_shape = df_clean.shape\n",
    "    print(f\"\\n=== {dataset_name.upper()} CLEANING SUMMARY ===\")\n",
    "    print(f\"Original shape: {original_shape}\")\n",
    "    print(f\"Final shape: {final_shape}\")\n",
    "    print(f\"Rows removed: {original_shape[0] - final_shape[0]}\")\n",
    "    print(f\"Remaining missing values: {df_clean.isnull().sum().sum()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean both datasets\n",
    "if df_airline is not None:\n",
    "    df_airline_clean = clean_dataset(df_airline, \"AIRLINE\")\n",
    "    print(f\"Clean airline dataset available as 'df_airline_clean'\")\n",
    "else:\n",
    "    print(\"Airline dataset not available for cleaning\")\n",
    "\n",
    "if df_carriers is not None:\n",
    "    df_carriers_clean = clean_dataset(df_carriers, \"CARRIERS\")\n",
    "    print(f\"Clean carriers dataset available as 'df_carriers_clean'\")\n",
    "else:\n",
    "    print(\"Carriers dataset not available for cleaning\")\n",
    "\n",
    "print(f\"\\n=== OVERALL CLEANING COMPLETED ===\")\n",
    "if df_airline is not None and df_carriers is not None:\n",
    "    print(f\"Both datasets cleaned successfully!\")\n",
    "    print(f\"- df_airline_clean: {df_airline_clean.shape}\")\n",
    "    print(f\"- df_carriers_clean: {df_carriers_clean.shape}\")\n",
    "elif df_airline is not None:\n",
    "    print(f\"Airline dataset cleaned: {df_airline_clean.shape}\")\n",
    "elif df_carriers is not None:\n",
    "    print(f\"Carriers dataset cleaned: {df_carriers_clean.shape}\")\n",
    "else:\n",
    "    print(\"No datasets were available for cleaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5159bc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>...</th>\n",
       "      <th>Month</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>1650</td>\n",
       "      <td>1545</td>\n",
       "      <td>65.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>DCA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N443US</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>1805</td>\n",
       "      <td>1610</td>\n",
       "      <td>175.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MCO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N755</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>WN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1950</td>\n",
       "      <td>1850</td>\n",
       "      <td>60.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1818.0</td>\n",
       "      <td>1823</td>\n",
       "      <td>1728</td>\n",
       "      <td>55.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MEM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UNKNOW</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1118</td>\n",
       "      <td>1030</td>\n",
       "      <td>48.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N785CA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ActualElapsedTime  AirTime  ArrDelay  ArrTime  CRSArrTime  CRSDepTime  \\\n",
       "0               53.0     32.0      -8.0   1642.0        1650        1545   \n",
       "1              164.0    155.0     -11.0   1754.0        1805        1610   \n",
       "2               60.0     84.0      15.0   2005.0        1950        1850   \n",
       "3               51.0     84.0      -5.0   1818.0        1823        1728   \n",
       "4               45.0     29.0       2.0   1120.0        1118        1030   \n",
       "\n",
       "   CRSElapsedTime CancellationCode  Cancelled  CarrierDelay  ...  Month  \\\n",
       "0            65.0                A          0           0.0  ...     10   \n",
       "1           175.0                A          0           0.0  ...     12   \n",
       "2            60.0                A          0           0.0  ...     12   \n",
       "3            55.0                A          0           0.0  ...      9   \n",
       "4            48.0                A          0           0.0  ...      6   \n",
       "\n",
       "   NASDelay  Origin  SecurityDelay TailNum  TaxiIn  TaxiOut  UniqueCarrier  \\\n",
       "0       0.0     DCA            0.0  N443US     7.0     14.0             US   \n",
       "1       0.0     MCO            0.0    N755     2.0      7.0             WN   \n",
       "2       0.0     ATL            0.0  UNKNOW     5.0     13.0             DL   \n",
       "3       0.0     MEM            0.0  UNKNOW     5.0     13.0             AA   \n",
       "4       0.0     CVG            0.0  N785CA     3.0     13.0             OH   \n",
       "\n",
       "   WeatherDelay  Year  \n",
       "0           0.0  2002  \n",
       "1           0.0  1999  \n",
       "2           0.0  1993  \n",
       "3           0.0  1989  \n",
       "4           0.0  2006  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e8af409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02Q</td>\n",
       "      <td>Titan Airways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04Q</td>\n",
       "      <td>Tradewind Aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05Q</td>\n",
       "      <td>Comlux Aviation, AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06Q</td>\n",
       "      <td>Master Top Linhas Aereas Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>07Q</td>\n",
       "      <td>Flair Airlines Ltd.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code                    Description\n",
       "0  02Q                  Titan Airways\n",
       "1  04Q             Tradewind Aviation\n",
       "2  05Q            Comlux Aviation, AG\n",
       "3  06Q  Master Top Linhas Aereas Ltd.\n",
       "4  07Q            Flair Airlines Ltd."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_carriers_clean.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
